{"cells":[{"cell_type":"markdown","metadata":{"id":"MZ-Jp3fA21CY"},"source":["## 1. Importing Libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehhB3h8Fncnl"},"outputs":[],"source":["import os\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26902,"status":"ok","timestamp":1725848524402,"user":{"displayName":"Sameer Hussain","userId":"05631691693334713311"},"user_tz":-345},"id":"QxqrWZY8ngyW","outputId":"53b34f12-1960-4983-bd3f-0c4fd15d9f7f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4077,"status":"ok","timestamp":1725848528476,"user":{"displayName":"Sameer Hussain","userId":"05631691693334713311"},"user_tz":-345},"id":"1lKMWTub1q66","outputId":"aad93803-7e93-4f6c-b12b-08a4b9791808"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}],"source":["import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer"]},{"cell_type":"markdown","metadata":{"id":"gh4NQ30828Iv"},"source":["## 2. Text Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1594,"status":"ok","timestamp":1725848530068,"user":{"displayName":"Sameer Hussain","userId":"05631691693334713311"},"user_tz":-345},"id":"9RNo9luV1gNt","outputId":"675feeb5-dbd7-41b3-bb91-dcb7be9360e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["['reduces', 'word', 'root', 'form', 'improving', 'text', 'analysis', 'porter', 'stemmer', 'algorithm', 'commonly', 'used', 'good']\n"]}],"source":["# Function to lowercase the text\n","def lower_case(text):\n","    return text.lower()\n","\n","# Function to remove URLs\n","def remove_urls(text):\n","    return re.sub(r'http\\S+', '', text)\n","\n","# Function to remove non-word characters (punctuation)\n","def non_word(text):\n","    return re.sub(r'\\W+', ' ', text)\n","\n","# Function to remove digits\n","def remove_digits(text):\n","    return re.sub(r'\\d+', '', text)\n","\n","# Function to tokenize the text\n","def tokenize(text):\n","    return word_tokenize(text)\n","\n","# Function to remove stop words\n","def stop_word(tokens):\n","    stop_words = set(stopwords.words('english'))\n","    return [token for token in tokens if token not in stop_words]\n","\n","# Function to lemmatize the tokens\n","def lemmatize_tokens(tokens):\n","    lemmatizer = nltk.WordNetLemmatizer()\n","    return [lemmatizer.lemmatize(token) for token in tokens]\n","\n","# Main text processing function\n","def process_text(text):\n","    text = lower_case(text)\n","    text = remove_urls(text)\n","    text = non_word(text)\n","    text = remove_digits(text)\n","    tokens = tokenize(text)\n","    tokens = stop_word(tokens)\n","    tokens = lemmatize_tokens(tokens)\n","    return tokens\n","\n","# Sample input\n","text = \"@ The reduces words to their root form, improving text analysis. The Porter Stemmer algorithm is commonly used 988234good283. https://t.co/GDrqU22YpT\"\n","\n","print(process_text(text))\n"]},{"cell_type":"markdown","metadata":{"id":"N1Hpm0Q-3HCt"},"source":["## 3. Importing Folders containg .txt Files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ro0Dx4e3GLe"},"outputs":[],"source":["# Folder containing the text files\n","folder_path = '/content/drive/MyDrive/PBS BSc IT/Year 3/Information Retrievsl System (TECH 400)/Week 2/Assignment Lab/Text Documents'"]},{"cell_type":"markdown","metadata":{"id":"IYlkULP83bIn"},"source":["## 4. Creating Dictonary for Tokenized Documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GNxELALv3Zdy"},"outputs":[],"source":["documents = {}\n","\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.txt'):\n","        with open(os.path.join(folder_path, filename), 'r') as file:\n","            text = file.read()\n","            documents[filename] = process_text(text)"]},{"cell_type":"markdown","metadata":{"id":"79rYIDmV3o8-"},"source":["## 5. Creating an Inverted Index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Sn8cNotn1gL"},"outputs":[],"source":["from collections import defaultdict\n","\n","inverted_index = defaultdict(list)\n","\n","# Build the inverted index\n","for doc, tokens in documents.items():\n","    for token in set(tokens):  # Use set to avoid duplicates\n","        inverted_index[token].append(doc)\n"]},{"cell_type":"markdown","metadata":{"id":"SLMfsuoa3xBP"},"source":["## 6. Query Processing (AND Queries)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OFPIJbNLn6S6"},"outputs":[],"source":["def and_query(query, index):\n","    query_tokens = query.lower().split()\n","\n","    # Get the list of documents for each term in the query\n","    doc_lists = [set(index[token]) for token in query_tokens if token in index]\n","\n","    if not doc_lists:\n","        return []\n","\n","    # Find intersection of all document lists (AND operation)\n","    result_docs = set.intersection(*doc_lists)\n","    return result_docs\n"]},{"cell_type":"markdown","metadata":{"id":"eWs2iaFR35pH"},"source":["## 7. Testing the Queries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"X4MIxfxnn7ez"},"outputs":[{"name":"stdout","output_type":"stream","text":["No documents found.\n","Documents found: david_fincher.txt\n"]}],"source":["while True:\n","    query = input(\"Enter AND query (or 'exit' to stop): \")\n","    if query == 'exit':\n","        break\n","    results = and_query(query, inverted_index)\n","    if results:\n","        print(f\"Documents found: {', '.join(results)}\")\n","    else:\n","        print(\"No documents found.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNfbDfernApp"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMHlXJaORtAsl66Y0+DoEsi","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}